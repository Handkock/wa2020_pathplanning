%todo Warum Anwendung im Funktionsprinzipienteil?

\chapter{Funktionsprizipien von Pfadplanungsalgorithmen}

Pfadplanung im Hinblick auf Graphentheorie kann informiert und uninformiert sein. Uninformierte Pfadplanung, auch ``Blindsuche'' genannt, wird in alle Richtungen durchgeführt. Im Gegensatz dazu wird in der informierten Pfadplanung die Richtung zum Ziel geschätzt und in diese Richtung weitergesucht \cite[S.38]{Man18}.

\section{Uninformierte Algorithmen}
Algorithmen dieser Gruppe werden verwendet, wenn keine Informationen über die Entfernung vom Startknoten $s$ zum Zielknoten $d$ bekannt sind. Sie garantieren, dass der kürzeste Pfad gefunden wird, falls ein solcher Pfad existiert. Weil uninformierte Algorithmen über alle möglichen erreichbaren Knoten gehen, gibt es einen großen Bedarf an Speicherplatz und Leistung \cite[S. 232, 235f.]{Noo15}. Die am meisten verwendeten Algorithmen dieser Gruppe sind die Breitensuche, die Tiefensuche und der Algorithmus von Dijkstra.

\subsection{Breitensuche}
\label{sec:bfs}
Die Breitensuche (engl. Breadth-First Search, BFS) ist ein simpler Suchalgorithmus, welcher in Graphen angewendet werden kann \cite[S.594]{Cormen.2009}. Der Algorithmus kann den kürzesten Pfad zwischen zwei Punkten bestimmen. Dazu ist er in der Lage einen Pfad zu finden, der mit möglichst wenig anderen Pfaden kollidiert, oder bestmöglich Hindernisse vermeidet \cite{Lee.1961}. BFS dient als Grundmuster für Shortest Path Algorithmen in ungerichteten Graphen \cite{Ottmann.2017}. Die Breitensuche kann jedoch sowohl in gerichteten als auch ungerichteten Graphen genutzt werden. Sie hat eine Laufzeit von $O(V + E)$ \cite[S.597]{Cormen.2009}.

Die Breitensuche durchläuft einen Graphen systematisch und schrittweise in alle Richtungen. Gegeben ist ein Graph $G = (V, E)$, mit einem festgelegten Startknoten $s$, sowie ein Inkrement $k=1$. Nun werden folgende Schritte in einer Schleife ausgeführt:
\begin{itemize}
\item[1.] Finde alle Knoten, welche $k$ Kanten von $s$ entfernt sind.
\item[2.] Rechne $k + 1$.
\end{itemize}
Diese Schritte werden so lange wiederholt, bis alle Knoten im Graphen gefunden wurden, die von $s$ erreicht werden können. Wird ein Knoten von BFS entdeckt, so wird die Distanz zum Startknoten $s$ berechnet. Anschließend wird der Knoten zu einem speziellen ``Breitensuchbaum'' hinzugefügt, welcher alle vom Startknoten aus erreichbaren Knoten beinhaltet. Die Zweige des Baums stellen den kürzesten Pfad von $s$ zu den Knoten des Baumes dar \cite[S.594]{Cormen.2009}.

Die Breitensuche kann bei Pfadplanung in einem Labyrinthspiel verwendet werden \cite[S. 3ff.]{PBAS18}. Dieser Algorithmus sichert aber nicht die beste Suche im Hinblick auf Rechenleistung und Geschwindigkeit \cite[S. 6]{PBAS18}. Außerdem können BFS-Algorithmus und seine Hybridversion \cite{HT13} für die Traversierung der Graphen von Graphikprozessoren benutzt werden \cite{MGG12}.

\subsection{Tiefensuche}
\label{sec:dfs}
Die Tiefensuche (engl. Depth-First Search, DFS) stellt das Gegenstück zum Prinzip der Breitensuche dar. Sie untersucht eine Kette von Folgeknoten bis das Ende der Kette erreicht wurde. Grundlegend lässt sich der Algorithmus in zwei Phasen unterteilen, die ``Suche nach tieferliegenden Knoten''(1) und das ``sogenannte „Backtracking''(2) \cite{Tarjan.1972}:
\begin{itemize}
	\item[(1)] DFS untersucht den zuletzt gefundenen Knoten auf ausgehende Kanten. Existiert eine unentdeckte Kante, folgt DFS der Kante zum nächsten Knoten. Existiert keine weitere Kante, wechselt der Algorithmus in Phase 2.
	\item[(2)] DFS setzt zum überliegenden Knoten zurück. Dieser wird auf eine unentdeckte Kante untersucht. Gibt es keine unentdeckte Kante, setzt DFS erneut zurück. Existiert eine weitere Kante, wechselt der Algorithmus zurück in Phase 1.	
\end{itemize}
Das Verfahren der Tiefensuche endet sobald der Algorithmus zum Startknoten $s$ zurückgesetzt hat und bei $s$ keine unentdeckten Kanten verbleiben. Beim Entdecken eines Knoten wird die Distanz zu $s$ berechnet, und der kürzeste Pfad zu $s$ in einen ``Tiefensuchbaum'' eingepflegt (vergleiche Breitensuchbaum). Bei der Tiefensuche können jedoch mehrere Bäume entstehen, welche dann einen sogenannten ``Tiefensuchwald'' formen \cite[S.603]{Cormen.2009}.
Für das Zwischenspeichern der gefundenen Knoten bietet sich ein Stack an, da der Algorithmus selbst nach dem Prinzip ``Last In - First Out'' funktioniert \cite{Tarjan.1972}. Die Tiefensuche hat eine Laufzeit von $\Theta(V + E)$ \cite[S.606]{Cormen.2009}.

DFS kann Labyrinthe generieren und einen Weg daraus finden \cite{KB15}. Die Tiefensuche wird jedoch aufgrund ihres blinden Prinzips selten für Pfadplanung angewendet.


\subsection{Dijkstras Algorithmus}
\label{sec:dijkstra}
In seiner Arbeit ``Two Problems in Connexion with Graphs'' stellt Dijkstra zwei Probleme dar \cite{Dijkstra.1959}. Das erste Problem ist die Konstruktion eines Baums mit den kürzesten Wegen zwischen den Knoten eines Graphen als Zweigen (vergleiche Breitensuchbaum). Das andere ist die Suche nach dem kürzesten Weg zwischen zwei Knoten (vergleiche Problem des kürzesten Pfades). \\
Zur Lösung des Problems des kürzesten Pfades zwischen zwei Knoten $s$ und $d$ wird eine Menge Knoten $R = \{r_0, r_1, ...\}$ definiert, wobei die Knoten aus $R$ auf dem kürzesten Pfad zwischen $s$ und $d$ liegen. Da ein Knoten $r_i \in R$ Teil des kürzesten Wegs zwischen $s$ und $d$ ist, ist auch der Weg zwischen $s$ und $r_i$ minimal. Es werden kontinuierlich Knoten aus $R$ gesucht, die weiter von $s$ entfernt sind, bis der Zielknoten $d$ erreicht wurde.

Zur schrittweisen Lösung nutzt der Algorithmus drei verschiedene Mengen von Knoten. Menge $A = \{a_0, a_1, ...\}$ sind die Knoten, für die die minimale Distanz vom Startknoten $s$ aus bekannt ist. Menge $B = \{b_0, b_1, ...\}$ sind jene Knoten, die direkt mit einem Knoten aus $A$ verbunden sind, aber nicht Teil von $A$ sind. In $C = \{c_0, c_1, ...\}$ befinden sich alle übrigen Knoten.
Zusätzlich wird eine Baumstruktur angelegt, welche das erste von Dijkstra beschriebene Problem löst. Der Baum besitzt drei Hauptzweige. In den ersten beiden Zweigen $Alpha = \{\alpha_0, \alpha_1, ...\}$ und $Beta = \{\beta_0, \beta_1, ...\}$ befinden sich jeweils die Pfade vom Startknoten $s$ zu den Knoten der Mengen $A$ und $B$. Pro Knoten der Menge $B$ wird jedoch nur ein Pfad zu $s$ gespeichert. Im dritten Zweig $Gamma = \{\gamma_0, \gamma_1, ...\}$ befinden sich alle übrigen Pfade. Zusätzlich nutzen wir die in \ref{Kostenfunktion} definierte Kostenfunktion zur Minimierung der Länge einzelner Pfade.

Zu Beginn des Lösungsprozesses liegen alle Knoten in $C$, die Mengen $A$ und $B$ sind leer. Der Startknoten $s$ wird in $A$ abgelegt. Nun werden wiederholend folgende zwei Schritte ausgeführt:
\begin{itemize}
	\item[1.] Es werden alle Pfade $H = \{h_0, h_1, ...\}$ zwischen dem zuletzt in $A$ abgelegten Knoten $v$ und der Teilmenge von Knoten aus $R$, die in $B$ oder $C$ liegen, überprüft.\\ Liegt ein Knoten $r_i$ in $B$, so wird überprüft, ob $c(h_i) < c(s,r_i)$, mit $h_i = \left(s, v, r_i\right)$. Es wird also überprüft, ob der Weg über den neuen Knoten kürzer ist als die bislang kürzeste bekannte Pfad zwischen $s$ und $r_i$. Sollte dies der Fall sein, ersetzt $h_i$ den im zweiten Zweig abgelegten Pfad zwischen $s$ und $r_i$. \\Liegt $r_i$ in $C$, so wird der Knoten in $B$ verschoben und $h_i$ dem zweiten Zweig hinzugefügt.
	\item[2.] Werden für die Knoten $B$ lediglich Pfade aus $Alpha$ und $Beta$ betrachtet, besitzt jeder Knoten aus $B$ eine feste Länge zu $s$. Der Knoten aus $B$ mit der kürzesten Distanz zu $s$ wird nach $A$ verschoben und sein Pfad aus $Beta$ im ersten Zweig des Baums abgelegt.
\end{itemize}
Diese Schritte werden so lange wiederholt bis Zielknoten $d$ in $A$ verschoben wurde. \\ \\	
Der Algorithmus hat eine Komplexität von $O(n^2)$\footnote{$n = |V|$} \cite[S.5]{Madkour.2017}. 1984 schlugen Fredman und Tarjan die Nutzung eines Fibonacci Heaps zur Verbesserung der Laufzeit des Dijkstra-Algorithmus vor \cite{Fredman.1987}. Unter Anwendung eines solche F-Heaps stellt der Dijkstra-Algorithmus den asymptotisch schnellsten bekannten Algorithmus zur Lösung des Shortest Path Problems in gerichteten Graphen dar \cite{Schmitz.2019}.  Die Komplexität beträgt $O(n\ log\ n + m)$\footnote{$m = |E|$} \cite[S.5]{Madkour.2017}.

Der Suchalgorithmus von Dijkstra und dessen Erweiterungen besitzen ein sehr breites Anwendungsspektrum, zum Beispiel in Transportnetzwerken in sicheren \cite{BAN17} und unsicheren Umgebungen \cite{DCZM12}. Außerdem kann der Algorithmus Verwendung in Satellitennetzwerken \cite{HH15} und in Anwendungsnetzwerken \cite{JYA14} finden.

\section{Informierte Algorithmen}
\label{sec:bestsearch}
Die sogenannte Bestensuche (engl. informed best-first search)
ist ein verbreiteter Ansatz, um die Suchzeit nach dem kürzesten Pfad anhand heuristischer Informationen zu verkürzen. Dabei wird versucht jedem Knotenpunkt in einem Graphen einen Wert zuzuweisen. Anhand dieser Wertzuweisung wird die Erkundung des Graphen in die Richtung des vielversprechendsten Kandidaten fortgeführt \cite{RinaDechterandJudeaPearl.1983}.

\subsection{Heuristiken}
Um die Suche nach einer Lösung effizienter zu machen, werden heuristische Methoden angewendet. Als Heuristik wird die Methodik bezeichnet, mit begrenzetem Wissen eine Lösung zu finden. Dabei werden Schätzwerte angenähert, mit denen die Algorithmen schneller zum Ziel kommen, indem sie nur einen Teil der verfügbaren Pfade untersuchen \cite{RinaDechterandJudeaPearl.1983}.

\subsubsection{Metriken}
Eine Metrik ist eine Funktion, welche den Abstand zwischen zwei Elementen in dem von ihr untersuchten Raum bestimmt. Für die Distanzabschätzung der heuristischen Methoden gibt es verschiedene Ansätze. Verwendet werden hauptsächlich folgende Metriken.

\begin{itemize}
\item[1.] Die \textit{Manhattendistanz} misst den Abstand zwischen zwei Knotenpunkten in einem Raster, indem sie die horizontale und vertikale Distanz aufeinander addiert.

\item[2.] Die \textit{Diagonaldistanz} arbeitet mit der Annahme, dass Agenten sich in die diagonale, genauso wie in die horizontale und vertikale Richtung bewegen können.

\item[3.] Der \textit{Chebyshev-Abstand} ist eine Variante der Diagonaldistanz. Bei ihr wird angenommen, dass die Kosten für die diagonale Traversierung der horizontalen und vertikalen entsprechen.

\item[4.] Es gibt zwei Varianten der \textit{euklidischen Distanz}, die einfache und die quadrierte. Die euklidische Distanz berechnet den Abstand zwischen zwei Knoten als Punkte in einem kartesischen Koordinatensystem. Da die Berechnung der Wurzel für die Abstandsberechnung rechenintensiv ist, wird in der alternativen Variante auf die Ziehung der Wurzel verzichtet und der quadrierte euklidische Abstand verwendet\cite[S.44 ff.]{You19}.

\end{itemize}
\subsection{A*}
\label{sec:astar}
Um den kürzesten Pfad mit dem geringsten Aufwand zu finden, profitiert ein Suchalgorithmus von informierten Entscheidungen für die Untersuchung der Knotenpunkte. Untersucht er Knotenpunkte, die offensichtlich nicht zum Ziel führen können, verschwendet er Ressourcen. Untersucht er andererseits Knoten nicht, welche zum kürzesten Pfad beitragen, führt der Algorithmus nicht zum richtigen Ergebnis. In diesem Zusammenhang wird häufig der A* Algorithmus untersucht.

Es sei ein gewichteter Graph  $G = (V, E)$ gegeben, der den Startknoten $s \in V$ und eine nichtleere Menge aus Zielknoten $T \subseteq V$ habe. Das Problem des optimalen Pfades besteht nun darin, den Pfad vom Startknoten $s$ zu einem Knoten $t$ aus der Zielmenge $T$ mit den geringsten Kosten zu finden.
Die Kosten errechnen sich aus den Gewichten der besuchten Kanten, mit $c(s,t)$ \cite{RinaDechterandJudeaPearl.1983}.

A* benutzt die Funktion $f(u) = g(u) + h(u)$.
\begin{itemize}
\item Die Funktion $g(u)$ spiegelt die additiven Kosten des momentanen Pfades von dem Startknoten $s$ zu dem jetzigen Knoten $u$ wieder, also $c(s,u)$.
\item Die Funktion $h(u)$ liefert eine heuristische Einschätzung, welche die Kosten des Restpfades zum Zielknoten schätzt \cite{RinaDechterandJudeaPearl.1983}.
\end{itemize}

Der Algorithmus A* hat den folgenden Ablauf:
\begin{itemize}
\item[1.] Der Startknoten $s$ wird als \textit{offen} markiert und die Funktion $f(s)$ berechnet. Als \textit{offen} werden die Knoten bezeichnet, die von dem Algorithmus besucht und für die Untersuchung freigeschaltet worden sind.
\item[2.] Derjenige offene Knoten $u$ wird ausgewählt, für den die Funktion $f(u)$
den geringsten Wert liefert. Anschließend werden beliebige angrenzende Knoten ausgewählt, aber immer zugunsten jedes Knotens aus der Zielmenge $T$.
\item[3.] Es wird überprüft, ob sich der aktuelle Knoten $u$ in der Zielmenge befindet. Ist das der Fall, wird er als \textit{geschlossen} markiert und der Algorithmus terminiert. Ein Knoten $u$ gilt als \textit{geschlossen} sobald die Berechnung der Funktion $f(u)$ für ihn durchgeführt wurde.
\item[4.]
Falls der Knoten $u$ sich nicht in der Zielmenge befindet, wird er als \textit{geschlossen} markiert und alle Nachfolger von $u$ erkundet. Dann wird $f(u)$ für jeden Nachfolger berechnet und jeder Nachfolger als \textit{offen} markiert, der nicht als \textit{geschlossen} markiert wurde. Gibt es nun Nachfolgeknoten die als \textit{geschlossen} markiert sind, für welche die Funktion $f$ einen geringeren Wert liefert, werden diese Knoten als \textit{offen} markiert. Daraufhin wird Schritt zwei wieder ausgeführt. Solange, bis der Algorithmus terminiert und der kürzeste Pfad durch den Graphen gefunden wurde \cite{HartNilssonandRaphael.1968}.
\end{itemize}

A* sei laut Hart et al. \cite{HartNilssonandRaphael.1968} als optimal anzusehen, da der Algorthmus nicht mehr Knotenpunkte als andere Algorithmen untersuchen muss, um auf eine Lösung zu kommen. In ihrer Arbeit ``The optimality of A* revisited'' können Dechter et al. aber zeigen, dass die Optimalität des A*-Algorithmus nicht bewiesen werden kann \cite{RinaDechterandJudeaPearl.1983}.
